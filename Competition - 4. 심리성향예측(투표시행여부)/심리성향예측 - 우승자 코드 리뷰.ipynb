{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수 생성 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**부족했던점**\n",
    "\n",
    "- 설문 데이터 자체에 대한 도메인 접근 방법을 잘 하지 못했음\n",
    "    - 무응답 설문에 대한 처리\n",
    "    - 카테고리 변수에서 응답값이 비 이상적인 부분 처리 미흡\n",
    "    - 설문지 데이터 특유의 성격을 반영하는 피처를 생성하는 것에 대한 미흡\n",
    "        - 이부분은 코드 공유 및 토론에서 많이 레퍼함\n",
    "   <br></br>\n",
    "<br></br>\n",
    "\n",
    "- 그 외에 변수 생성과정에서는 다른 팀과 큰 차별점이 없음\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "- 이상치 처리, 결측치 처리가 모델링 앞서 전처리 단계에서 역시나 중요하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selection modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 피처의 10%씩 소거하면서 backward feature selection 방법론을 고안\n",
    "# 또한 교차검증과 하이퍼 파라미터를 사용하지 않고 기본 파라미터로만 random_state를 고정해서\n",
    "# 모델을 작성\n",
    "\n",
    "# 아래와 같은 방식으로 random_state를 4개를 선택한 후\n",
    "# 각기 다른 4개의 random_state로 4개의 추론 값을 구함\n",
    "def lgbm_rfe_4040(x_data, y_data, ratio=0.9, min_feats=40):\n",
    "    feats = x_data.columns.tolist()\n",
    "    archive = pd.DataFrame(columns=['model', 'n_feats', 'feats', 'score'])\n",
    "    while True:\n",
    "        model = LGBMClassifier(objective = 'binary', num_iterations=10**4)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_data[feats], y_data, random_state=4040)\n",
    "        model.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = val_pred[:,1]\n",
    "        score = roc_auc_score(y_val, val_pred)\n",
    "        n_feats = len(feats)\n",
    "        print(n_feats, score)\n",
    "        archive = archive.append({'model': model, 'n_feats': n_feats, 'feats': feats, 'score': score}, ignore_index=True)\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=feats).sort_values(ascending=False)        \n",
    "        next_n_feats = int(n_feats * ratio)\n",
    "        if next_n_feats < min_feats:\n",
    "            break\n",
    "        else:\n",
    "            feats = feat_imp.iloc[:next_n_feats].index.tolist()\n",
    "    return archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_archive_4040 = lgbm_rfe_4040(x_train, y_train)\n",
    "\n",
    "model = LGBMClassifier(objective=\"binary\", num_iterations= 10**3)\n",
    "\n",
    "# 변수소거로 탐색한 변수들중에 7번째 row에 있는 변수들이 성능이 좋기 때문에 해당\n",
    "# 변수들만을 가지고 inference\n",
    "x_train_1 = x_train[lgbm_archive_4040.iloc[7,2]]\n",
    "\n",
    "model.fit(x_train_1, y_train)\n",
    "\n",
    "pred_y1 = model.predict_proba(test[lgbm_archive_4040.iloc[7,2]])\n",
    "pred_y1 = pred_y1[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치로 구현\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "drop_list = ['QaE', 'QbE', 'QcE', 'QdE', 'QeE',\n",
    "             'QfE', 'QgE', 'QhE', 'QiE', 'QjE',\n",
    "             'QkE', 'QlE', 'QmE', 'QnE', 'QoE',\n",
    "             'QpE', 'QqE', 'QrE', 'QsE', 'QtE',\n",
    "             'index', 'hand']\n",
    "replace_dict = {'education': str, 'engnat': str, 'married': str, 'urban': str}\n",
    "train_data = pd.read_csv('../data/train.csv')\n",
    "test_data = pd.read_csv('../data/test_x.csv')\n",
    "train_data = train_data.drop(train_data[train_data.familysize > 50].index)\n",
    "train_y = train_data['voted']\n",
    "train_x = train_data.drop(drop_list + ['voted'], axis=1)\n",
    "test_x = test_data.drop(drop_list, axis=1)\n",
    "train_x = train_x.astype(replace_dict)\n",
    "test_x = test_x.astype(replace_dict)\n",
    "train_x = pd.get_dummies(train_x)\n",
    "test_x = pd.get_dummies(test_x)\n",
    "train_y = 2 - train_y.to_numpy()\n",
    "train_x = train_x.to_numpy()\n",
    "test_x = test_x.to_numpy()\n",
    "\n",
    "train_y_t = torch.tensor(train_y, dtype=torch.float32)\n",
    "train_x_t = torch.tensor(train_x, dtype=torch.float32)\n",
    "test_x_t = torch.tensor(test_x, dtype=torch.float32)\n",
    "train_x_t[:, :20] = (train_x_t[:, :20] - 3.) / 2.\n",
    "test_x_t[:, :20] = (test_x_t[:, :20] - 3.) / 2\n",
    "train_x_t[:, 20] = (train_x_t[:, 20] - 5.) / 4.\n",
    "test_x_t[:, 20] = (test_x_t[:, 20] - 5.) / 4.\n",
    "train_x_t[:, 21:31] = (train_x_t[:, 21:31] - 3.5) / 3.5\n",
    "test_x_t[:, 21:31] = (test_x_t[:, 21:31] - 3.5) / 3.5\n",
    "test_len = len(test_x_t)\n",
    "\n",
    "N_REPEAT = 5\n",
    "N_SKFOLD = 7\n",
    "N_EPOCH = 48\n",
    "BATCH_SIZE = 72\n",
    "LOADER_PARAM = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True\n",
    "}\n",
    "prediction = np.zeros((test_len, 1), dtype=np.float32)\n",
    "\n",
    "for repeat in range(N_REPEAT):\n",
    "\n",
    "    skf, tot = StratifiedKFold(n_splits=N_SKFOLD, random_state=repeat, shuffle=True), 0.\n",
    "    for skfold, (train_idx, valid_idx) in enumerate(skf.split(train_x, train_y)):\n",
    "        train_idx, valid_idx = list(train_idx), list(valid_idx)\n",
    "        train_loader = DataLoader(TensorDataset(train_x_t[train_idx, :], train_y_t[train_idx]),\n",
    "                                  shuffle=True, drop_last=True, **LOADER_PARAM)\n",
    "        valid_loader = DataLoader(TensorDataset(train_x_t[valid_idx, :], train_y_t[valid_idx]),\n",
    "                                  shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "        test_loader = DataLoader(TensorDataset(test_x_t, torch.zeros((test_len,), dtype=torch.float32)),\n",
    "                                 shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "        model = nn.Sequential(\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(91, 180, bias=False),\n",
    "            nn.LeakyReLU(0.05, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(180, 32, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1)\n",
    "        ).to(DEVICE)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.20665], device=DEVICE))\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=5e-3, weight_decay=7.8e-2)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=N_EPOCH // 6, eta_min=4e-4)\n",
    "        prediction_t, loss_t = np.zeros((test_len, 1), dtype=np.float32), 1.\n",
    "\n",
    "        # for epoch in range(N_EPOCH):\n",
    "        for epoch in tqdm(range(N_EPOCH), desc='{:02d}/{:02d}'.format(skfold + 1, N_SKFOLD)):\n",
    "            model.train()\n",
    "            for idx, (xx, yy) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "                pred = model(xx).squeeze()\n",
    "                loss = criterion(pred, yy)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step(epoch + idx / len(train_loader))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                running_acc, running_loss, running_count = 0, 0., 0\n",
    "                for xx, yy in valid_loader:\n",
    "                    xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "                    pred = model(xx).squeeze()\n",
    "                    loss = criterion(pred, yy)\n",
    "                    running_loss += loss.item() * len(yy)\n",
    "                    running_count += len(yy)\n",
    "                    running_acc += ((torch.sigmoid(pred) > 0.5).float() == yy).sum().item()\n",
    "                # print('R{:02d} S{:02d} E{:02d} | {:6.4f}, {:5.2f}%'\n",
    "                #       .format(repeat + 1, skfold + 1, epoch + 1, running_loss / running_count,\n",
    "                #               running_acc / running_count * 100))\n",
    "\n",
    "                if running_loss / running_count < loss_t:\n",
    "                    loss_t = running_loss / running_count\n",
    "                    for idx, (xx, _) in enumerate(test_loader):\n",
    "                        xx = xx.to(DEVICE)\n",
    "                        pred = (2. - torch.sigmoid(model(xx).detach().to('cpu'))).numpy()\n",
    "                        prediction_t[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction)), :] \\\n",
    "                            = pred[:, :].copy()\n",
    "        prediction[:, :] += prediction_t[:, :].copy() / (N_REPEAT * N_SKFOLD)\n",
    "        tot += loss_t\n",
    "    print('R{} -> {:6.4f}'.format(repeat + 1, tot / N_SKFOLD))\n",
    "\n",
    "df = pd.read_csv('../data/sample_submission.csv')\n",
    "df.iloc[:, 1:] = prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 앙상블 따로 validation 추론값을 뽑지 않았다면 리더보드 통해서\n",
    "# 가중치 최적화"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
