# 대회 회고

- 대회요강: 설문 데이터로 각 투표권자들의 투표 시행 여부를 예측하는 대회.
- 대회평가: AUC
- 대회결과
  - public: 47/581
  - private: 97/581

## 방법론
  1. **데이터 전처리**
      - 결측치 처리 x
        - 데이터 결측치가 없었기 때문에 따로 처리하지 않음
      - 전반적인 데이터 처리
        - 상위 코드들을 리뷰해본 결과 특정 카테고리에서 비이상적인 수치값이 있엇는데 그부분을 제거하지 못함
        - 설문 응답에 걸리는 시간이 왜도가 심한 것을 확인하여 log화 과정을 거침(성능 향상)
      - 인코딩
        - 아래의 세가지 방법론으로 검증셋 결과 추론
          - label encoding
          - target mean encoding
          - dummy
        - label encoding의 성능이 높은 것을 확인
  2. **EDA, FE**
      - EDA를 기반으로 변수 생성
        - education, married 관련 변수로 성능향상
        - 해당 변수들은 분포도를 통해서 변수 생성
      - EDA를 통해서 Treshhold를 찾는데 집중함
      - 기본적인 통계변수들을 생성
  3. **Modeling**
      - 사용한 모델
        - LGBM
        - XGB
        - CATBoost
      - 모델 방법론
        - CV
          - 5 fold를 사용
        - ood_preds AUC가 높았던 데이터셋을 구성하여 사용
        - training_auc, validation_auc를 동시에 고려
          - 항상 training_auc보다 validation_auc가 안좋게 나왔기 때문에 과적합을 계속 의심함
  4. **Model parameter 최적화**
      - 사용된 방법론
        - RandomGridSearch
        - Bayesian optimization
      - 최종 최적화 파라미터
        - 베이지안 최적화 방식으로 하이퍼파라미터 최적화를 진행
        - RandomGridSearch보다 높은 리더보드 성능을 보여줌
        - 베이지안 파라미터 최적화를 공부하면서 배웠던 비교적 복잡하지 않은 데이터셋에서 좋은 성능을 보여줌
  5. **Ensemble**
      - 리더보드 성능이 좋았던 결과값들을 가중치 앙상블을 진행
      - CATBoost 성능은 좋지 않았기 때문에 LGBM, XGB 두가지 모델로 앙상블을 진행
  6. **Inference**
      - 검증셋 결과 inference결과와 리더보드 결과의 상관관계가 없었기 때문에 리더보드를 통해서 성능 검증



## 개선점 및 고려점(**우승자 코드를 리뷰해보고 작성함**)
  - 우승자 코드로 배웠던 부분
    - 다양한 방법론이 존재했지만 모델의 일반화 부분이 상당히 중요하다는 것을 느낌
      - 현재 이 대회에서 생성한 결과값은 리더보드 성능이 가장좋은 결과값 두개를 0.7/0.3 가중치 앙상블을 진행했음
      - 우승자 코드를 통해서 배울 수 있었던 것은 random_state를 다양하게 부여하면서 N개의 서로 다른 random_state모델을 생성한 다음 앙상블하는 방식을 배울 수 있었음
      - 대회의 결과가 shakeup이 컸는데 중간에 코드공유로 올라온 뉴럴넷 모델을 앙상블한 사람들이 대부분 상위권을 차지한 것을 보고 뉴럴넷 모델로 추론한 결과값이 상당히 로버스트한 것을 알 수 있었음
      - Feature selection방법론도 이론으로는 알고 있었으나 실제로 구현해보는 것이 꺼려졌는데 생각보다 쉽게 구현할 수 있는 것에 놀랐음(랜덤성을 반영하면 더 좋은 모델을 만들 수 있을듯)
      - 우승자 코드는 서로 다른 random_state 4개의 Default 파라미터 LGBM을 4개 만들어 단순 산술평균 앙상블을 진행했는데 해당 부분에 교차검증 + 베이지안 최적화 방법론을 접목시키면 좀 더 성능이 높고 견고한 모델을 만들 수 있을 것이라 생각이 되었음

  - **최종 리뷰**
    - 아직 모델링을 하는데 테크니컬한 부분이 부족한 것을 느낌
    - 모델을 생성할 때 리더보드 결과에만 치중하면 안된다는 것을 다시 한번 느낌... 모델 일반화가 굉장히 중요!
    - validation set을 잘 만드는 것이 중요!
    - 테스트 데이터를 예측할 때 oof_preds의 중요성을 느낌 꼭 저장하자!(앙상블 가중치 추출하기 위해서)
    - 전통적인 정형화된 데이터는 LGBM이 비용대비 성능이 최고라고 생각되었는데, 다음 대회부터는 딥러닝 모델도 같이 앙상블하면 좋겠다고 생각함
    - 이번 대회를 참여하면서 분석 -> 모델링 -> 추론 파이프라인에 신경을 썼다고 생각이 되었는데, 대회 후반으로 갈수록 엉망으로 바뀜... 다음부턴 명확하게 계획을 세우기로 함
    - 리더보드와 검증 결과와의 수치 차이에 상관관계가 없다면 문제라고 인식하고 어떻게 하면 해결할 수 있는지 고민을 해볼 것
    - 추가적으로 validation으로 변수 추출하는 과정에서 train, test를 분할해서 80%에 최적화된 변수들을 만들었는데 CV를 진행할 때는 분할하지 않고 그대로 out_of_fold랑 비교해서 성능을 추출하면 좋을 것 같음
    - 그리고 모델 일반화 부분에서 문제를 해결할 때 train과 test의 분포를 비교한 뒤 그 분포를 맞춰준 다음 문제를 해결해야 하는 부분도 다음엔 접목 시켜야 할 필요성을 느꼈음
      - 해당 대회에서는 train, test의 분포를 비교해본 결과 학습데이터와 예측데이터간의 분포차이가 없었음



