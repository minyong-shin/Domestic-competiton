{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:23:54.074378Z",
     "start_time": "2021-01-17T04:23:54.068648Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc, rcParams\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm\n",
    "import datetime\n",
    "import math\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from itertools import chain, repeat\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "rcParams['figure.figsize'] = (16, 8)\n",
    "rc('font', family='AppleGothic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:23:54.232808Z",
     "start_time": "2021-01-17T04:23:54.229982Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_base_path = './data/train'\n",
    "te_base_path = './data/test'\n",
    "submission_path = './submission'\n",
    "infer_path = './inferencedata'\n",
    "train_path = './trainingdata'\n",
    "cv_lb_path = './cv_lb_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:23:54.595761Z",
     "start_time": "2021-01-17T04:23:54.393639Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(tr_base_path,'train.csv'))\n",
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "# 파일명 불러오는 것: os.listdir과 다른점은 경로를 그대로 붙여서 불러와줌\n",
    "# test_files = glob.glob('./data/test/*.csv')\n",
    "\n",
    "# test load \n",
    "t_test = []\n",
    "\n",
    "for i in range(81):\n",
    "    file_path = './data/test/' + str(i) + '.csv'\n",
    "    temp = pd.read_csv(file_path)\n",
    "    t_test.append(temp)\n",
    "    \n",
    "test = pd.concat(t_test)\n",
    "df_test = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p-pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:23:55.521557Z",
     "start_time": "2021-01-17T04:23:55.517967Z"
    }
   },
   "outputs": [],
   "source": [
    "def base_preprocess(data, n, n2) : \n",
    "    \n",
    "    # 원래 방법대로 한다면, 마지막 48개행은 target2에 대해 미지의 값을 가진게 아닌가?\n",
    "    # step1 : 하루 뒤, 이틀 뒤 target 값 가져오기 \n",
    "    data['1day_after_target'] = data.shift(n)['TARGET']\n",
    "    data['2day_after_target'] = data.shift(n2)['TARGET']\n",
    "    \n",
    "    # step2 : 7일간의 segment를 할당하여 예측을 진행 \n",
    "    \n",
    "    data = data.dropna(axis=0)\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:23:56.507854Z",
     "start_time": "2021-01-17T04:23:56.477728Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = base_preprocess(train, -48, -96)\n",
    "df_train_day23 = base_preprocess(train, -96, -144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필령's FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:23:57.197279Z",
     "start_time": "2021-01-17T04:23:57.192182Z"
    }
   },
   "outputs": [],
   "source": [
    "test_day = df_test['Day'].copy() \n",
    "\n",
    "label_list = []\n",
    "\n",
    "for i in range(1,568) : \n",
    "    label_list.append([i]*48)\n",
    "\n",
    "label_list = [item for sublist in label_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:23:57.829043Z",
     "start_time": "2021-01-17T04:23:57.809505Z"
    }
   },
   "outputs": [],
   "source": [
    "def zenith_angel_def(data, merge_data, is_train=True, label_lists=None) : \n",
    "    \n",
    "    if is_train != True : \n",
    "        \n",
    "        data['Day'] = label_list\n",
    "        merge_data['Day'] = label_list\n",
    "    \n",
    "    # 시간 및 분을 합쳐주는 함수\n",
    "    def time_pil(data) : \n",
    "\n",
    "        texts = str(data['Hour']) + str(data['Minute'])[:1]\n",
    "\n",
    "        return(texts)\n",
    "\n",
    "    data['GHI_less'] = data['DHI'] + data['DNI']\n",
    "    data['Time'] = data[['Hour','Minute']].apply(lambda x: time_pil(x), axis=1)\n",
    "    data['GHI_less'] = data['GHI_less'].astype('int') \n",
    "\n",
    "    f = data[data['GHI_less']>0].groupby(['Day']).head(1)[['Day','Time','T','GHI_less']]\n",
    "    f.columns = ['Day','First_time','First_T','First_GHI_less']\n",
    "\n",
    "    l = data[data['GHI_less']>0].groupby(['Day']).tail(1)[['Day','Time','T','GHI_less']]\n",
    "    l.columns = ['Day','Last_time','Last_T','Last_GHI_less']\n",
    "    \n",
    "    f_l = pd.merge(f, l, how='inner', on=['Day']) \n",
    "    \n",
    "    def sun_hour(data) : \n",
    "\n",
    "        hours = (int(str(data['Last_time'])[:2]) - int(str(data['First_time'])[0]))*60\n",
    "\n",
    "        return(hours)\n",
    "\n",
    "    def sun_minute(data) : \n",
    "\n",
    "        minutes = (int(str(data['Last_time'][2])) - int(str(data['First_time'][1])))*10\n",
    "\n",
    "        return(minutes)\n",
    "\n",
    "    f_l['SUN_hour'] = f_l[['First_time','Last_time']].apply(lambda x:sun_hour(x), axis=1)\n",
    "    f_l['SUN_minute'] = f_l[['First_time','Last_time']].apply(lambda x:sun_minute(x), axis=1)\n",
    "    \n",
    "    f_l['SUN_time'] = f_l['SUN_hour'] + f_l['SUN_minute']\n",
    "    \n",
    "    temp = pd.merge(data, f_l, how='inner', on='Day')\n",
    "    temp['Time'] = temp[['Hour','Minute']].apply(lambda x: time_pil(x), axis=1)\n",
    "    temp[['Time','First_time','Last_time']] = temp[['Time','First_time','Last_time']].astype('int')\n",
    "    \n",
    "    temp2 = temp[(temp['Time']>=temp['First_time']) & (temp['Time']<=temp['Last_time'])]  \n",
    "    \n",
    "    zenith_angle_lists = []\n",
    "\n",
    "    for day in temp2.Day.unique() : \n",
    "\n",
    "        temp3 = temp2[temp2['Day']==day]\n",
    "        zenith_angles = np.arange(0,181,180/(temp3['SUN_time'].iloc[0]/30))\n",
    "\n",
    "        for num in range(len(zenith_angles)) : \n",
    "\n",
    "            if zenith_angles[num] < 90 : \n",
    "                zenith_angles[num] = 90 - zenith_angles[num]\n",
    "                \n",
    "            elif zenith_angles[num] == 0 :\n",
    "                zenith_angles[num] = 1\n",
    "\n",
    "            else : \n",
    "                zenith_angles[num] = zenith_angles[num] - 90\n",
    "\n",
    "        zenith_angle_lists.append(zenith_angles)\n",
    "        \n",
    "    zenith_angle_lists = [item for sublist in zenith_angle_lists for item in sublist]\n",
    "    temp2['zenith_angle'] = zenith_angle_lists\n",
    "    \n",
    "    final = pd.merge(merge_data, temp2[['Day','Hour','Minute','zenith_angle']],\n",
    "                    how='left', on=['Day','Hour','Minute'])\n",
    "    \n",
    "    final = final.fillna(90) \n",
    "    \n",
    "    final = pd.merge(final, temp2[['Day','SUN_time']].drop_duplicates(),\n",
    "                    how='inner', on=['Day'])\n",
    "    \n",
    "    return(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:24:06.913594Z",
     "start_time": "2021-01-17T04:23:59.508666Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = zenith_angel_def(data = df_train, merge_data = df_train\n",
    "                            , is_train=True, label_lists=None)\n",
    "\n",
    "df_train_day23 = zenith_angel_def(data = df_train_day23, merge_data = df_train_day23\n",
    "                            , is_train=True, label_lists=None)\n",
    "\n",
    "df_test = zenith_angel_def(data = df_test, merge_data = df_test\n",
    "                            , is_train=False, label_lists=label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:24:10.745880Z",
     "start_time": "2021-01-17T04:24:06.915370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape : (52464, 16)\n",
      "df_test shape : (27216, 14)\n"
     ]
    }
   ],
   "source": [
    "def custom_ghi(data) : \n",
    "    \n",
    "    answer = data['DHI'] + (data['DNI']*math.cos(data['zenith_angle']))\n",
    "    \n",
    "    return answer \n",
    "\n",
    "df_train['GHI'] = df_train[['DHI','DNI','zenith_angle']].apply(lambda x: custom_ghi(x), axis=1)\n",
    "df_train_day23['GHI'] = df_train_day23[['DHI','DNI','zenith_angle']].apply(lambda x: custom_ghi(x), axis=1)\n",
    "df_test['GHI'] = df_test[['DHI','DNI','zenith_angle']].apply(lambda x: custom_ghi(x), axis=1)\n",
    "\n",
    "print('df_train shape :', df_train.shape)\n",
    "print('df_test shape :', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:24:10.751547Z",
     "start_time": "2021-01-17T04:24:10.749111Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['Day'] = test_day.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:28:07.714047Z",
     "start_time": "2021-01-17T04:28:07.699327Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_2day_variable(df_train, rolling_num) : \n",
    "    \n",
    "    hour_lists = []\n",
    "\n",
    "    numbers = list(np.arange(0,24,1))\n",
    "    n_list = [2]*24\n",
    "\n",
    "    hours_range = list(chain.from_iterable((repeat(number, n) for (number, n) in zip(numbers, n_list))))\n",
    "\n",
    "    for (hours,minutes) in zip(hours_range,list(np.arange(0,31,30))*30) : \n",
    "\n",
    "        hour_lists.append(df_train[(df_train['Hour']==hours) & (df_train['Minute']==minutes)])\n",
    "\n",
    "    for num in range(len(hour_lists)) : \n",
    "\n",
    "        hour_lists[num][f'{rolling_num}days_mean_DHI'] = hour_lists[num]['DHI'].rolling(rolling_num).mean()\n",
    "        hour_lists[num][f'{rolling_num}days_mean_DNI'] = hour_lists[num]['DNI'].rolling(rolling_num).mean()\n",
    "#         hour_lists[num][f'{rolling_num}days_mean_T'] = hour_lists[num]['T'].rolling(rolling_num).mean()\n",
    "        #hour_lists[num][f'{rolling_num}days_mean_RH'] = hour_lists[num]['RH'].rolling(rolling_num).mean()\n",
    "        hour_lists[num][f'{rolling_num}days_mean_WS'] = hour_lists[num]['WS'].rolling(rolling_num).mean() \n",
    "        hour_lists[num][f'{rolling_num}days_mean_TARGET'] = hour_lists[num]['TARGET'].rolling(rolling_num).mean()\n",
    "        hour_lists[num][f'{rolling_num}days_mean_SUN_time'] = hour_lists[num]['SUN_time'].rolling(rolling_num).mean()\n",
    "        hour_lists[num][f'{rolling_num}days_mean_zenith_angle'] = hour_lists[num]['zenith_angle'].rolling(rolling_num).mean()\n",
    "        hour_lists[num][f'{rolling_num}days_mean_GHI'] = hour_lists[num]['GHI'].rolling(rolling_num).mean()\n",
    "        \n",
    "        # expanding\n",
    "#         hour_lists[num][f'{rolling_num}days_mean_DHI_expand'] = hour_lists[num]['DHI'].expanding(rolling_num).mean()\n",
    "#         hour_lists[num][f'{rolling_num}days_mean_DNI_expand'] = hour_lists[num]['DNI'].expanding(rolling_num).mean()\n",
    "#         #hour_lists[num][f'{rolling_num}days_mean_T'] = hour_lists[num]['T'].rolling(rolling_num).mean()\n",
    "#         #hour_lists[num][f'{rolling_num}days_mean_RH'] = hour_lists[num]['RH'].rolling(rolling_num).mean()\n",
    "#         hour_lists[num][f'{rolling_num}days_mean_WS_expand'] = hour_lists[num]['WS'].expanding(rolling_num).mean() \n",
    "#         hour_lists[num][f'{rolling_num}days_mean_TARGET_expand'] = hour_lists[num]['TARGET'].expanding(rolling_num).mean()\n",
    "#         hour_lists[num][f'{rolling_num}days_mean_SUN_time_expand'] = hour_lists[num]['SUN_time'].expanding(rolling_num).mean()\n",
    "#         hour_lists[num][f'{rolling_num}days_mean_zenith_angle_expand'] = hour_lists[num]['zenith_angle'].expanding(rolling_num).mean()\n",
    "#         hour_lists[num][f'{rolling_num}days_mean_GHI_expand'] = hour_lists[num]['GHI'].expanding(rolling_num).mean()\n",
    "\n",
    "        # diff 변수 추가\n",
    "        hour_lists[num]['2days_mean_DHI{}_diff'.format(rolling_num)] = hour_lists[num]['DHI']-hour_lists[num][f'{rolling_num}days_mean_DHI']\n",
    "        hour_lists[num]['2days_mean_DNI{}_diff'.format(rolling_num)] = hour_lists[num]['DNI']-hour_lists[num][f'{rolling_num}days_mean_DNI']\n",
    "        hour_lists[num]['2days_mean_T{}_diff'.format(rolling_num)] = hour_lists[num]['T']-hour_lists[num]['T'].rolling(rolling_num).mean()\n",
    "#         hour_lists[num]['2days_mean_WS{}_diff'.format(rolling_num)] = hour_lists[num]['WS']-hour_lists[num]['2days_mean_WS_rolling{}'.format(rolling_num)]\n",
    "#         hour_lists[num]['2days_mean_RH{}_diff'.format(rolling_num)] = hour_lists[num]['RH']-hour_lists[num]['2days_mean_RH_rolling{}'.format(rolling_num)]\n",
    "        hour_lists[num]['2days_mean_TARGET{}_diff'.format(rolling_num)] = hour_lists[num]['TARGET']-hour_lists[num][f'{rolling_num}days_mean_TARGET']\n",
    "        hour_lists[num]['2days_mean_SUN_time{}_diff'.format(rolling_num)] = hour_lists[num]['SUN_time']-hour_lists[num][f'{rolling_num}days_mean_SUN_time']\n",
    "        hour_lists[num]['2days_mean_zenith_angle{}_diff'.format(rolling_num)] = hour_lists[num]['zenith_angle']-hour_lists[num][f'{rolling_num}days_mean_zenith_angle']\n",
    "        hour_lists[num]['2days_mean_GHI{}_diff'.format(rolling_num)] = hour_lists[num]['GHI']-hour_lists[num][f'{rolling_num}days_mean_GHI']\n",
    "        \n",
    "\n",
    "    df_train = pd.concat(hour_lists).sort_index() \n",
    "    \n",
    "    return(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:28:09.664071Z",
     "start_time": "2021-01-17T04:28:08.558397Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = train_2day_variable(df_train, rolling_num=3)\n",
    "df_train_day23 = train_2day_variable(df_train_day23, rolling_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:28:32.945734Z",
     "start_time": "2021-01-17T04:28:32.927883Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_2day_variable(df_test, rolling_num) : \n",
    "    \n",
    "    label_list = []\n",
    "\n",
    "    for i in range(81) : \n",
    "        label_list.append([i]*336)\n",
    "\n",
    "    label_list = [item for sublist in label_list for item in sublist]\n",
    "\n",
    "    df_test['label'] = label_list \n",
    "\n",
    "    test_dataset = []\n",
    "\n",
    "    for label_num in df_test.label.unique() : \n",
    "\n",
    "        hour_lists = []\n",
    "        numbers = list(np.arange(0,24,1))\n",
    "        n_list = [2]*24\n",
    "        df_test2 = df_test[df_test['label']==label_num]\n",
    "\n",
    "        hours_range = list(chain.from_iterable((repeat(number, n) for (number, n) in zip(numbers, n_list))))\n",
    "\n",
    "        for (hours,minutes) in zip(hours_range,list(np.arange(0,31,30))*30) : \n",
    "            \n",
    "            hour_lists.append(df_test2[(df_test2['Hour']==hours) & (df_test2['Minute']==minutes)])\n",
    "\n",
    "        for num in range(len(hour_lists)) : \n",
    "            \n",
    "            hour_lists[num][f'{rolling_num}days_mean_DHI'] = hour_lists[num]['DHI'].rolling(rolling_num).mean()\n",
    "            hour_lists[num][f'{rolling_num}days_mean_DNI'] = hour_lists[num]['DNI'].rolling(rolling_num).mean()\n",
    "            #hour_lists[num][f'{rolling_num}days_mean_T'] = hour_lists[num]['T'].rolling(rolling_num).mean()\n",
    "            #hour_lists[num][f'{rolling_num}days_mean_RH'] = hour_lists[num]['RH'].rolling(rolling_num).mean()\n",
    "            hour_lists[num][f'{rolling_num}days_mean_WS'] = hour_lists[num]['WS'].rolling(rolling_num).mean()\n",
    "            hour_lists[num][f'{rolling_num}days_mean_TARGET'] = hour_lists[num]['TARGET'].rolling(rolling_num).mean()\n",
    "            hour_lists[num][f'{rolling_num}days_mean_SUN_time'] = hour_lists[num]['SUN_time'].rolling(rolling_num).mean()\n",
    "            hour_lists[num][f'{rolling_num}days_mean_zenith_angle'] = hour_lists[num]['zenith_angle'].rolling(rolling_num).mean()\n",
    "            hour_lists[num][f'{rolling_num}days_mean_GHI'] = hour_lists[num]['GHI'].rolling(rolling_num).mean()\n",
    "            \n",
    "            # expanding 성능 엄청 나빠짐...\n",
    "#             hour_lists[num][f'{rolling_num}days_mean_DHI_expand'] = hour_lists[num]['DHI'].expanding(rolling_num).mean()\n",
    "#             hour_lists[num][f'{rolling_num}days_mean_DNI_expand'] = hour_lists[num]['DNI'].expanding(rolling_num).mean()\n",
    "#             #hour_lists[num][f'{rolling_num}days_mean_T'] = hour_lists[num]['T'].rolling(rolling_num).mean()\n",
    "#             #hour_lists[num][f'{rolling_num}days_mean_RH'] = hour_lists[num]['RH'].rolling(rolling_num).mean()\n",
    "#             hour_lists[num][f'{rolling_num}days_mean_WS_expand'] = hour_lists[num]['WS'].expanding(rolling_num).mean()\n",
    "#             hour_lists[num][f'{rolling_num}days_mean_TARGET_expand'] = hour_lists[num]['TARGET'].expanding(rolling_num).mean()\n",
    "#             hour_lists[num][f'{rolling_num}days_mean_SUN_time_expand'] = hour_lists[num]['SUN_time'].expanding(rolling_num).mean()\n",
    "#             hour_lists[num][f'{rolling_num}days_mean_zenith_angle_expand'] = hour_lists[num]['zenith_angle'].expanding(rolling_num).mean()\n",
    "#             hour_lists[num][f'{rolling_num}days_mean_GHI_expand'] = hour_lists[num]['GHI'].expanding(rolling_num).mean()\n",
    "            \n",
    "            # diff 변수 추가\n",
    "            hour_lists[num]['2days_mean_DHI{}_diff'.format(rolling_num)] = hour_lists[num]['DHI']-hour_lists[num][f'{rolling_num}days_mean_DHI']\n",
    "            hour_lists[num]['2days_mean_DNI{}_diff'.format(rolling_num)] = hour_lists[num]['DNI']-hour_lists[num][f'{rolling_num}days_mean_DNI']\n",
    "            hour_lists[num]['2days_mean_T{}_diff'.format(rolling_num)] = hour_lists[num]['T']-hour_lists[num]['T'].rolling(rolling_num).mean()\n",
    "    #         hour_lists[num]['2days_mean_WS{}_diff'.format(rolling_num)] = hour_lists[num]['WS']-hour_lists[num]['2days_mean_WS_rolling{}'.format(rolling_num)]\n",
    "    #         hour_lists[num]['2days_mean_RH{}_diff'.format(rolling_num)] = hour_lists[num]['RH']-hour_lists[num]['2days_mean_RH_rolling{}'.format(rolling_num)]\n",
    "            hour_lists[num]['2days_mean_TARGET{}_diff'.format(rolling_num)] = hour_lists[num]['TARGET']-hour_lists[num][f'{rolling_num}days_mean_TARGET']\n",
    "            hour_lists[num]['2days_mean_SUN_time{}_diff'.format(rolling_num)] = hour_lists[num]['SUN_time']-hour_lists[num][f'{rolling_num}days_mean_SUN_time']\n",
    "            hour_lists[num]['2days_mean_zenith_angle{}_diff'.format(rolling_num)] = hour_lists[num]['zenith_angle']-hour_lists[num][f'{rolling_num}days_mean_zenith_angle']\n",
    "            hour_lists[num]['2days_mean_GHI{}_diff'.format(rolling_num)] = hour_lists[num]['GHI']-hour_lists[num][f'{rolling_num}days_mean_GHI']\n",
    "\n",
    "        temp = pd.concat(hour_lists)\n",
    "        test_dataset.append(temp)\n",
    "        \n",
    "    df_test = pd.concat(test_dataset).reset_index().sort_values(['label','index'])\n",
    "    df_test = df_test.drop(['index'],axis=1).reset_index(drop=True) \n",
    "    \n",
    "    return(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:29:10.350071Z",
     "start_time": "2021-01-17T04:28:33.754569Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = test_2day_variable(df_test, rolling_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T03:23:15.777791Z",
     "start_time": "2021-01-16T03:23:15.776015Z"
    }
   },
   "outputs": [],
   "source": [
    "# expanding rolling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final p-pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:29:46.130329Z",
     "start_time": "2021-01-17T04:29:46.113790Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['RH']!=100]\n",
    "df_train_day23 = df_train_day23[df_train_day23['RH']!=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:29:47.571342Z",
     "start_time": "2021-01-17T04:29:47.520784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape : (51142, 26)\n",
      "df_test shape : (19440, 29)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_train = df_train.drop(['Day','Minute','GHI_less','Time'], axis=1)\n",
    "\n",
    "df_train_day23 = df_train_day23.dropna()\n",
    "df_train_day23 = df_train_day23.drop(['Day','Minute','GHI_less','Time'], axis=1)\n",
    "\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "df_test2 = df_test[df_test['Day']==6]\n",
    "df_test2 = df_test2.drop(['Day','Minute','GHI_less','Time'], axis=1)\n",
    "\n",
    "df_test_day23 = df_test[df_test['Day']==5]\n",
    "df_test_day23 = df_test_day23.drop(['Day','Minute','GHI_less','Time'], axis=1)\n",
    "\n",
    "df_test2 = df_test2.drop(['label'],axis=1)\n",
    "df_test_day23 = df_test_day23.drop(['label'],axis=1)\n",
    "\n",
    "print('df_train shape :', df_train.shape)\n",
    "print('df_test shape :', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T13:01:37.747382Z",
     "start_time": "2021-01-12T13:01:37.698175Z"
    }
   },
   "outputs": [],
   "source": [
    "# # minute도 포함해서 한번 진행해보기\n",
    "# df_train = df_train.dropna()\n",
    "# df_train = df_train.drop(['Minute','Day'], axis=1)\n",
    "# # df_train = df_train.drop(['Day'], axis=1)\n",
    "\n",
    "# df_train_day23 = df_train_day23.dropna()\n",
    "# df_train_day23 = df_train_day23.drop(['Minute','Day'], axis=1)\n",
    "# # df_train_day23 = df_train_day23.drop(['Day'], axis=1)\n",
    "\n",
    "# df_test = df_test.dropna()\n",
    "# df_test2 = df_test[df_test['Day']==6]\n",
    "# df_test2 = df_test2.drop(['Day','Minute'], axis=1)\n",
    "\n",
    "# df_test_day23 = df_test[df_test['Day']==5]\n",
    "# df_test_day23 = df_test_day23.drop(['Day','Minute'], axis=1)\n",
    "\n",
    "# df_test2 = df_test2.drop(['label'],axis=1)\n",
    "# df_test_day23 = df_test_day23.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:30:24.115762Z",
     "start_time": "2021-01-17T04:30:24.113399Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = df_test2\n",
    "X_test_day23 = df_test_day23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:30:25.740744Z",
     "start_time": "2021-01-17T04:30:24.672974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20210117_133024\n"
     ]
    }
   ],
   "source": [
    "time_str = datetime.datetime.strftime(\n",
    "    datetime.datetime.today(),\n",
    "    '%Y%m%d_%H%M%S'\n",
    ")\n",
    "print(time_str)\n",
    "df_train.to_csv(\n",
    "    os.path.join(train_path, f'training_{time_str}.csv'), \n",
    "    index=False\n",
    ")\n",
    "\n",
    "X_test.to_csv(\n",
    "    os.path.join(infer_path, f'inference_{time_str}.csv'), \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T04:30:26.856620Z",
     "start_time": "2021-01-17T04:30:25.743303Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_day23.to_csv(\n",
    "    os.path.join(train_path, f'training_{time_str}_day23.csv'), \n",
    "    index=False\n",
    ")\n",
    "\n",
    "X_test_day23.to_csv(\n",
    "    os.path.join(infer_path, f'inference_{time_str}_day23.csv'), \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
