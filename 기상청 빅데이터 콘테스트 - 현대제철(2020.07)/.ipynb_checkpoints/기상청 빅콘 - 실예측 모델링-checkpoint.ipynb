{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "\n",
    "'''plotting'''\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc, font_manager\n",
    "import seaborn as sns\n",
    "\n",
    "'''sys library'''\n",
    "#plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "rc('font',family=\"NanumSquareR\")\n",
    "\n",
    "'''modeling'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from ggplot import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.stats as st\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "\n",
    "#-*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Data Import***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid data\n",
    "valid = pd.read_csv('data/참가번호6자리.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test data\n",
    "train_24_recent= pd.read_csv('data/train24_MY.csv',index=False)\n",
    "train_48_recen = pd.read_csv('data/train48_MY.csv',index=False)\n",
    "dj_ts_aws_recent= pd.read_csv('data/test_MY.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Function***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 분할\n",
    "def train_test(df,target_variable,size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = target_variable),df[target_variable],test_size = size, random_state = 0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def proba_to_int(value_ls,cut_off):\n",
    "    \n",
    "    preds = []\n",
    "    for i in range(len(value_ls)):\n",
    "        \n",
    "        if value_ls[i] >= cut_off:\n",
    "            preds.append(1)\n",
    "        else:\n",
    "            preds.append(0)\n",
    "            \n",
    "            \n",
    "    return preds\n",
    "\n",
    "def nan_preprocessing(df,col):\n",
    "    col_value = []\n",
    "    for i in range(len(df)):\n",
    "        if i != 0 and str(df[col].iloc[i]) == 'nan':\n",
    "\n",
    "            if str(df[col].iloc[i-1]) == 'nan':\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "\n",
    "                for j in range(i+1,len(df)):\n",
    "                    if str(df[col].iloc[j]) != 'nan':\n",
    "                        interval = abs(df[col].iloc[i-1] - df[col].iloc[j])\n",
    "                        cnt = j - (i-1)\n",
    "\n",
    "                        value = interval / cnt \n",
    "\n",
    "                        value2 = df[col].iloc[i-1]\n",
    "\n",
    "                        if df[col].iloc[i-1] < df[col].iloc[j]:\n",
    "                            right_left = 'left'\n",
    "\n",
    "                        else:\n",
    "                            right_left = 'right'\n",
    "\n",
    "                        for k in range(0,cnt - 1):\n",
    "\n",
    "                            if right_left == 'left':\n",
    "                                value2 += value\n",
    "                                col_value.append(value2)\n",
    "                            elif right_left == 'right':\n",
    "                                value2 -= value\n",
    "                                col_value.append(value2)\n",
    "\n",
    "                        break\n",
    "\n",
    "\n",
    "                    elif str(df[col].iloc[j]) == 'nan':\n",
    "                        pass\n",
    "        else:\n",
    "            col_value.append(df[col].iloc[i])\n",
    "    return col_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***XGB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_classifier(df,test_df, target_variable, num_folds, cut_off, real_train = False):\n",
    "    \n",
    "    if real_train == False:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = target_variable),df[target_variable],test_size = 0.25, random_state = 0)\n",
    "\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "\n",
    "        oof_preds = np.zeros(X_train.shape[0])\n",
    "        test_preds = np.zeros(X_test.shape[0])\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "\n",
    "        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train,y_train)):\n",
    "\n",
    "            train_x, train_y = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "            valid_x, valid_y = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "            # 파라미터 삽입\n",
    "            '''params = {}base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.7, gamma=0.5, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.7, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=0.4, monotone_constraints='()', n_estimators=1000, n_jobs=0,\n",
    "              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.9,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None'''\n",
    "            \n",
    "\n",
    "        \n",
    "            clf = xgb.XGBClassifier(n_estimators = 1000)\n",
    "\n",
    "            # 모델 평가척도로 어떤것을 사용할 것인지\n",
    "            clf.fit(train_x, train_y, eval_set = [(train_x, train_y), (valid_x, valid_y)], \n",
    "                   eval_metric='auc', verbose= 100, early_stopping_rounds=300)\n",
    "\n",
    "            oof_preds[valid_idx] = clf.predict_proba(valid_x)[:,1]\n",
    "            test_preds += clf.predict_proba(X_test)[:,1] / folds.n_splits\n",
    "\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = X_train.columns\n",
    "            fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "            fold_importance_df[\"fold\"] = n_fold + 1\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "            print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "\n",
    "            del clf, train_x, train_y, valid_x, valid_y\n",
    "            gc.collect()\n",
    "\n",
    "        print('Full AUC score %.6f' % roc_auc_score(y_train, oof_preds))\n",
    "\n",
    "        feature_importance_fin = feature_importance_df[[\"feature\", \"importance\"]].\\\n",
    "                                groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        for i in range(len(test_preds)):\n",
    "            if test_preds[i] >= cut_off:\n",
    "\n",
    "                preds.append(1)\n",
    "            else:\n",
    "                preds.append(0)\n",
    "\n",
    "        print('Test AUC score : ', roc_auc_score(y_test, test_preds))\n",
    "        conf_matrix = confusion_matrix(y_test, preds,labels = [1,0])\n",
    "        \n",
    "        plt.figure(figsize = (16,12))\n",
    "        plt.barh(feature_importance_fin.index,feature_importance_fin['importance'])\n",
    "\n",
    "\n",
    "        return test_preds, preds, y_test, feature_importance_fin, conf_matrix\n",
    "    \n",
    "    elif real_train == True:\n",
    "        \n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "        \n",
    "        test_preds = np.zeros(test_df.shape[0])\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "        \n",
    "        X_train = df.drop(columns = target_variable)\n",
    "        y_train = df[target_variable]\n",
    "        oof_preds = np.zeros(X_train.shape[0])\n",
    "        \n",
    "        test_df = test_df[X_train.columns.tolist()] #컬럼 순서를 맞춰주기 위한 장치\n",
    "        \n",
    "        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train,y_train)):\n",
    "\n",
    "            train_x, train_y = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "            valid_x, valid_y = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "            # 파라미터 삽입\n",
    "            '''params = {}'''\n",
    "\n",
    "            clf = xgb.XGBClassifier(n_estimators= 1000)\n",
    "\n",
    "            # 모델 평가척도로 어떤것을 사용할 것인지\n",
    "            clf.fit(train_x, train_y, eval_set = [(train_x, train_y), (valid_x, valid_y)], \n",
    "                   eval_metric='auc', verbose= 100, early_stopping_rounds=300)\n",
    "\n",
    "            oof_preds[valid_idx] = clf.predict_proba(valid_x)[:,1]\n",
    "            test_preds += clf.predict_proba(test_df)[:,1] / folds.n_splits\n",
    "\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = X_train.columns\n",
    "            fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "            fold_importance_df[\"fold\"] = n_fold + 1\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "            print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "\n",
    "            del clf, train_x, train_y, valid_x, valid_y\n",
    "            gc.collect()\n",
    "\n",
    "        print('Full AUC score %.6f' % roc_auc_score(y_train, oof_preds))\n",
    "\n",
    "        feature_importance_fin = feature_importance_df[[\"feature\", \"importance\"]].\\\n",
    "                                groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        for i in range(len(test_preds)):\n",
    "            if test_preds[i] >= cut_off:\n",
    "\n",
    "                preds.append(1)\n",
    "            else:\n",
    "                preds.append(0)\n",
    "\n",
    "                \n",
    "        plt.figure(figsize = (16,12))\n",
    "        plt.barh(feature_importance_fin.index,feature_importance_fin['importance'])\n",
    "\n",
    "        return test_preds, preds, feature_importance_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Validation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 처리한 버전\n",
    "test_preds_xgb24, preds_xgb24, y_test_xgb24, feature_importance_fin_xgb24, conf_matrix_xgb24 = XGB_classifier(\\\n",
    "                                                                                        train_24_recent,\n",
    "                                                                                        dj_ts_aws_recent,\n",
    "                                                                                        'after24_loc_predict',\n",
    "                                                                                        5,\n",
    "                                                                                        0.5,\n",
    "                                                                                        real_train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 처리한 버전\n",
    "test_preds_xgb48, preds_xgb48, y_test_xgb48, feature_importance_fin_xgb48, conf_matrix_xgb48 = XGB_classifier(\\\n",
    "                                                                                        train_48_recent,\n",
    "                                                                                        dj_ts_aws_recent,\n",
    "                                                                                        'after48_loc_predict',\n",
    "                                                                                        5,\n",
    "                                                                                        0.5,\n",
    "                                                                                        real_train = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Real Test Prediction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_xgb24, preds_xgb24, feature_importance_fin_xgb24 = XGB_classifier(\\\n",
    "                                                            train_24_recent,\n",
    "                                                            dj_ts_aws_recent,\n",
    "                                                            'after24_loc_predict',\n",
    "                                                            5,\n",
    "                                                            0.5,\n",
    "                                                            real_train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_xgb48, preds_xgb48, feature_importance_fin_xgb48 = XGB_classifier(\\\n",
    "                                                            train_48_recent,\n",
    "                                                            dj_ts_aws_recent,\n",
    "                                                            'after48_loc_predict',\n",
    "                                                            5,\n",
    "                                                            0.5,\n",
    "                                                            real_train = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***XGB Grid Search***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "xgb_params = {\n",
    "        'min_child_weight': [0.2,0.4,0.5],\n",
    "        'gamma': [0.4,0.45,0.5],\n",
    "        'subsample': [0.8,0.9,0.93],\n",
    "        'colsample_bytree': [0.6,0.7, 0.8],\n",
    "        'max_depth': [ 4.5, 5, 5.5],\n",
    "        'learning_rate' : [0.6,0.65,0.7]\n",
    "        }\n",
    "\n",
    "#24시간 뒤의 결로현상을 예측하는 교차 모델\n",
    "param_comb = 5\n",
    "n = 5\n",
    "\n",
    "X = train_24_recent.drop(columns = 'after24_loc_predict')\n",
    "Y = train_24_recent['after24_loc_predict']\n",
    "\n",
    "folds= KFold(n_splits=n, shuffle = True, random_state = 1001)\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators = 1000)\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(xgb_clf, param_distributions=xgb_params, n_iter=param_comb, scoring='roc_auc', n_jobs=1, cv=folds.split(X,Y), verbose=10, random_state=1001 )\n",
    "\n",
    "# Here we go\n",
    "start_time = time.time() # timing starts from this point for \"start_time\" variable\n",
    "random_search_xgb.fit(X, Y)\n",
    "print('걸린 시간 : ', time.time() - start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------------------------')\n",
    "print(xgb_params)\n",
    "print('------------------------------------')\n",
    "print(random_search_xgb.best_estimator_)\n",
    "print('------------------------------------')\n",
    "print(random_search_xgb.best_params_)\n",
    "print('------------------------------------')\n",
    "print(random_search_xgb.best_score_)\n",
    "print('------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***LGBM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGBM_classifier(df, test_df, target_variable, num_folds,cut_off , real_train = False):\n",
    "    \n",
    "    if real_train == False:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = target_variable),df[target_variable],test_size = 0.25, random_state = 0)\n",
    "\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "\n",
    "        oof_preds = np.zeros(X_train.shape[0])\n",
    "        test_preds = np.zeros(X_test.shape[0])\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "\n",
    "        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train,y_train)):\n",
    "\n",
    "            train_x, train_y = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "            valid_x, valid_y = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "            # 파라미터 삽입\n",
    "            '''params = {}boosting_type='gbdt', class_weight='balanced',\n",
    "               colsample_bytree=0.8, gamma=0.4, importance_type='split',\n",
    "               learning_rate=0.6, max_depth=5, min_child_samples=20,\n",
    "               min_child_weight=0.5, min_split_gain=0.0,\n",
    "               n_estimators=1000, n_jobs=-1, num_leaves=31, objective=None,\n",
    "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "               subsample=0.8, subsample_for_bin=200000, subsample_freq=0'''\n",
    "            clf = lgb.LGBMClassifier(class_weight = 'balanced', n_estimators = 1000)\n",
    "\n",
    "            # 모델 평가척도로 어떤것을 사용할 것인지\n",
    "            clf.fit(train_x, train_y, eval_set = [(train_x, train_y), (valid_x, valid_y)], \n",
    "                   eval_metric='auc', verbose= 100, early_stopping_rounds=300)\n",
    "\n",
    "            oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:,1]\n",
    "            test_preds += clf.predict_proba(X_test, num_iteration = clf.best_iteration_)[:,1] / folds.n_splits\n",
    "\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = X_train.columns\n",
    "            fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "            fold_importance_df[\"fold\"] = n_fold + 1\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "            print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "\n",
    "            del clf, train_x, train_y, valid_x, valid_y\n",
    "            gc.collect()\n",
    "\n",
    "        print('Full AUC score %.6f' % roc_auc_score(y_train, oof_preds))\n",
    "\n",
    "        feature_importance_fin = feature_importance_df[[\"feature\", \"importance\"]].\\\n",
    "                                groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        for i in range(len(test_preds)):\n",
    "            if test_preds[i] >= cut_off:\n",
    "\n",
    "                preds.append(1)\n",
    "            else:\n",
    "                preds.append(0)\n",
    "\n",
    "        print('Test AUC score : ', roc_auc_score(y_test, test_preds))\n",
    "        conf_matrix = confusion_matrix(y_test, preds,labels = [1,0])\n",
    "        \n",
    "        plt.figure(figsize = (16,12))\n",
    "        plt.barh(feature_importance_fin.index,feature_importance_fin['importance'])\n",
    "\n",
    "\n",
    "        return test_preds, preds, y_test, feature_importance_fin, conf_matrix\n",
    "    \n",
    "    elif real_train == True:\n",
    "        \n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "        \n",
    "        test_preds = np.zeros(test_df.shape[0])\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "        \n",
    "        X_train = df.drop(columns = target_variable)\n",
    "        y_train = df[target_variable]\n",
    "        \n",
    "        oof_preds = np.zeros(X_train.shape[0])\n",
    "        \n",
    "        test_df = test_df[X_train.columns.tolist()] #컬럼 순서를 맞춰주기 위한 장치\n",
    "        \n",
    "        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train,y_train)):\n",
    "\n",
    "            train_x, train_y = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "            valid_x, valid_y = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "            # 파라미터 삽입\n",
    "            '''params = {}'''\n",
    "            clf = lgb.LGBMClassifier(class_weight = 'balanced', n_estimators = 1000)\n",
    "\n",
    "            # 모델 평가척도로 어떤것을 사용할 것인지\n",
    "            clf.fit(train_x, train_y, eval_set = [(train_x, train_y), (valid_x, valid_y)], \n",
    "                   eval_metric='auc', verbose= 100, early_stopping_rounds=300)\n",
    "\n",
    "            oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:,1]\n",
    "            test_preds += clf.predict_proba(test_df, num_iteration = clf.best_iteration_)[:,1] / folds.n_splits\n",
    "\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = X_train.columns\n",
    "            fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "            fold_importance_df[\"fold\"] = n_fold + 1\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "            print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "\n",
    "            del clf, train_x, train_y, valid_x, valid_y\n",
    "            gc.collect()\n",
    "\n",
    "        print('Full AUC score %.6f' % roc_auc_score(y_train, oof_preds))\n",
    "\n",
    "        feature_importance_fin = feature_importance_df[[\"feature\", \"importance\"]].\\\n",
    "                                groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        for i in range(len(test_preds)):\n",
    "            if test_preds[i] >= cut_off:\n",
    "\n",
    "                preds.append(1)\n",
    "            else:\n",
    "                preds.append(0)\n",
    "                \n",
    "        plt.figure(figsize = (16,12))\n",
    "        plt.barh(feature_importance_fin.index,feature_importance_fin['importance'])\n",
    "\n",
    "\n",
    "        return test_preds, preds, feature_importance_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Validation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_lgb24, preds_lgb24, y_test_lgb24, feature_importance_fin_lgb24, conf_matrix_lgb24 = LGBM_classifier(\\\n",
    "                                                                                train_24_recent,\n",
    "                                                                                dj_ts_aws_recent,\n",
    "                                                                                'after24_loc_predict',\n",
    "                                                                                5,\n",
    "                                                                                0.5,\n",
    "                                                                                real_train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_lgb48, preds_lgb48, y_test_lgb48, feature_importance_fin_lgb48, conf_matrix_lgb48 = LGBM_classifier(\\\n",
    "                                                                                train_48_recent,\n",
    "                                                                                dj_ts_aws_recent,\n",
    "                                                                                'after48_loc_predict',\n",
    "                                                                                5,\n",
    "                                                                                0.5,\n",
    "                                                                                real_train = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Real Test Prediction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_lgb24, preds_lgb24, feature_importance_fin_lgb24 = LGBM_classifier(\\\n",
    "                                                                                train_24_recent,\n",
    "                                                                                dj_ts_aws_recent,\n",
    "                                                                                'after24_loc_predict',\n",
    "                                                                                5,\n",
    "                                                                                0.5,\n",
    "                                                                                real_train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_lgb48, preds_lgb48, feature_importance_fin_lgb48 = LGBM_classifier(\\\n",
    "                                                                                train_48_recent,\n",
    "                                                                                dj_ts_aws_recent,\n",
    "                                                                                'after48_loc_predict',\n",
    "                                                                                5,\n",
    "                                                                                0.5,\n",
    "                                                                                real_train = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***LGBM Grid Search***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "lgb_params = {\n",
    "        'min_child_weight': [0.5],\n",
    "        'gamma': [0.4],\n",
    "        'subsample': [0.8],\n",
    "        'colsample_bytree': [0.8],\n",
    "        'max_depth': [5],\n",
    "        'learning_rate' : [0.6]\n",
    "        }\n",
    "\n",
    "#24시간 뒤의 결로현상을 예측하는 교차 모델\n",
    "param_comb = 5\n",
    "n = 5\n",
    "\n",
    "X = train_24_recent.drop(columns = 'after24_loc_predict')\n",
    "Y = train_24_recent['after24_loc_predict']\n",
    "\n",
    "folds= KFold(n_splits=n, shuffle = True, random_state = 1001)\n",
    "lgb_clf = lgb.LGBMClassifier(n_estimators = 1000, class_weight='balanced')\n",
    "\n",
    "random_search_lgb = RandomizedSearchCV(lgb_clf, param_distributions=lgb_params, n_iter=param_comb, scoring='roc_auc', n_jobs=1, cv=folds.split(X,Y), verbose=10, random_state=1001 )\n",
    "\n",
    "# Here we go\n",
    "start_time = time.time() # timing starts from this point for \"start_time\" variable\n",
    "random_search_lgb.fit(X, Y)\n",
    "print('걸린 시간 : ', time.time() - start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------------------------')\n",
    "print(lgb_params)\n",
    "print('------------------------------------')\n",
    "print(random_search_lgb.best_estimator_)\n",
    "print('------------------------------------')\n",
    "print(random_search_lgb.best_params_)\n",
    "print('------------------------------------')\n",
    "print(random_search_lgb.best_score_)\n",
    "print('------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Validation Ensemble Function***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_to_int(value_ls,cut_off):\n",
    "    \n",
    "    preds = []\n",
    "    for i in range(len(value_ls)):\n",
    "        \n",
    "        if value_ls[i] >= cut_off:\n",
    "            preds.append(1)\n",
    "        else:\n",
    "            preds.append(0)\n",
    "            \n",
    "            \n",
    "    return preds\n",
    "\n",
    "#proba 데이터를 넣어줘야함\n",
    "def validation_emd(lgb24,lgb48,xgb24,xgb48,y_test24,y_test48,cut_off):\n",
    "    lgb24 = lgb24\n",
    "    xgb24 = xgb24\n",
    "\n",
    "    lgb48 = lgb48\n",
    "    xgb48 = xgb48\n",
    "\n",
    "    lgb_xgb_emb24 = (lgb24 + xgb24) / 2\n",
    "    lgb_xgb_emb48 = (lgb48 + xgb48) / 2\n",
    "\n",
    "    emb24_pred = proba_to_int(lgb_xgb_emb24,cut_off)\n",
    "    emb48_pred = proba_to_int(lgb_xgb_emb48,cut_off)\n",
    "    \n",
    "    print('After 24 hour predict auc : ',roc_auc_score(y_test24,emb24_pred))\n",
    "    print('After 24 hour proba auc : ',roc_auc_score(y_test24,lgb_xgb_emb24))\n",
    "    \n",
    "    print('\\nAfter 48 hour predict auc : ',roc_auc_score(y_test48,emb48_pred))\n",
    "    print('After 48 hour proba auc : ',roc_auc_score(y_test48,lgb_xgb_emb48))\n",
    "    \n",
    "    \n",
    "    conf_matrix24 = confusion_matrix(y_test24,emb24_pred,labels = [1,0])\n",
    "    conf_matrix48 = confusion_matrix(y_test48,emb48_pred,labels = [1,0])\n",
    "    print('\\nCut Off : ', cut_off)\n",
    "    print('\\nAfter 24hour confusion matrix : \\n',conf_matrix24)\n",
    "    print('\\nAfter 48hour confusion matrix : \\n',conf_matrix48)\n",
    "    \n",
    "    \n",
    "    csi24 = conf_matrix24[0,0] / (conf_matrix24[0,0] + conf_matrix24[0,1] + conf_matrix24[1,0])\n",
    "    csi48 = conf_matrix48[0,0] / (conf_matrix48[0,0] + conf_matrix48[0,1] + conf_matrix48[1,0])\n",
    "    \n",
    "    print('\\nAfter 24hour CSI : ', csi24)\n",
    "    print('\\nAfter 48hour CSI : ', csi48)\n",
    "    return emb24_pred, emb48_pred\n",
    "\n",
    "def validation_emd2(lgb24,lgb48,xgb24,xgb48,rf24,rf48,y_test24,y_test48,n):\n",
    "    lgb24 = lgb24\n",
    "    xgb24 = xgb24\n",
    "    rf24 = rf24\n",
    "\n",
    "    lgb48 = lgb48\n",
    "    xgb48 = xgb48\n",
    "    rf48 = rf48\n",
    "\n",
    "    emb24 = (lgb24 + xgb24 + rf24) / n\n",
    "    emb48 = (lgb48 + xgb48 + rf48) / n\n",
    "\n",
    "    emb24_pred = proba_to_int(emb24)\n",
    "    emb48_pred = proba_to_int(emb48)\n",
    "    \n",
    "    conf_matrix24 = confusion_matrix(y_test24,emb24_pred,labels = [1,0])\n",
    "    conf_matrix48 = confusion_matrix(y_test48,emb48_pred,labels = [1,0])\n",
    "    \n",
    "    \n",
    "    print('After 24hour confusion matrix : \\n',conf_matrix24)\n",
    "    print('\\nAfter 48hour confusion matrix : \\n',conf_matrix48)\n",
    "    \n",
    "    csi24 = conf_matrix24[0,0] / (conf_matrix24[0,0] + conf_matrix24[0,1] + conf_matrix24[1,0])\n",
    "    csi48 = conf_matrix48[0,0] / (conf_matrix48[0,0] + conf_matrix48[0,1] + conf_matrix48[1,0])\n",
    "    \n",
    "    print('\\nAfter 24hour CSI : ', csi24)\n",
    "    print('\\nAfter 48hour CSI : ', csi48)\n",
    "    return emb24_pred, emb48_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb24_pred, emb48_pred = validation_emd(test_preds_lgb24,test_preds_lgb48,test_preds_xgb24,test_preds_xgb48,y_test_lgb24,y_test_lgb48,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Real Test Ensemble***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_ensemble(lgb24, lgb48, xgb24, xgb48):\n",
    "    lgb24 = lgb24\n",
    "    xgb24 = xgb24\n",
    "\n",
    "    lgb48 = lgb48\n",
    "    xgb48 = xgb48\n",
    "\n",
    "    lgb_xgb_emb24 = (lgb24 + xgb24) / 2\n",
    "    lgb_xgb_emb48 = (lgb48 + xgb48) / 2\n",
    "\n",
    "    emb24_pred = proba_to_int(lgb_xgb_emb24,0.1)\n",
    "    emb48_pred = proba_to_int(lgb_xgb_emb48,0.1)\n",
    "    \n",
    "    emb24_proba = lgb_xgb_emb24*100.0\n",
    "    emb48_proba = lgb_xgb_emb48*100.0\n",
    "    \n",
    "    return emb24_pred,emb48_pred,emb24_proba,emb48_proba\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb24_pred, emb48_pred, emb24_proba,emb48_proba = real_ensemble(test_preds_lgb24,test_preds_lgb48,test_preds_xgb24,test_preds_xgb48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid['X24H_COND_LOC'] = emb24_pred\n",
    "valid['X48H_COND_LOC'] = emb48_pred\n",
    "\n",
    "valid['X24H_COND_LOC_PROB'] = emb24_proba\n",
    "valid['X48H_COND_LOC_PROB'] = emb48_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.to_csv('data/203675.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off = [0.6,0.5,0.4,0.3,0.2,0.1,0.09,0.08,0.07,0.06,0.05,0.04,0.03,0.02,0.01]\n",
    "csi =     [3.3,5.3,6.7,9.5,12, 15.8,18.19,20.59,22.78,23.91,23.6,21.12,20.46,19.87,17.99]\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(cut_off,csi)\n",
    "plt.axvline(0.06,color = 'b',linestyle = ':')\n",
    "plt.title('Cut-Off 조정에 따른 CSI변화')\n",
    "plt.xlabel('Cut-Off',fontweight = 'bold')\n",
    "plt.ylabel('CSI',fontweight = 'bold')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
